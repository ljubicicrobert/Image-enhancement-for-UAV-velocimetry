{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<< Back to MAIN notebook](main.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"image-colorspace\"></a>\n",
    "# 4 Image colorspace\n",
    "\n",
    "A **colorspace** is an organizational model of image data, i.e., the way visual information is handled inside the memory, as well as saved to and retrieved from storage. In general, different image formats can use different colorspace models - while JPEG images usually use RGB (Red-Green-Blue) model, they can, for example, use CMYK (Cyan-Magenta-Yellow-Key; Key=Black) model instead. As it will be shown in this section, image enhancement can benefit greatly from manipulating images in different colorspace models and accessing different kinds of information stored within."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "4.1 [RGB/BGR](#rgb-bgr)<br/>\n",
    "4.2 [Grayscale](#grayscale)<br/>\n",
    "4.3 [HSV](#hsv)<br/>\n",
    "4.4 [L\\*a\\*b\\*](#lab)<br/>\n",
    "4.5 [Conclusions](#conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from os import mkdir\n",
    "from os.path import exists, dirname\n",
    "from axes_tiein import on_lims_change\n",
    "\n",
    "# Use [%matplotlib widget] inside JupyterLab,\n",
    "# and [%matplotlib notebook] for Jupyter Notebook\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rgb-bgr\"></a>\n",
    "## 4.1 RGB/BGR\n",
    "\n",
    "RGB and BGR are the most commonly used (so-called additive) colorspace models. RGB model contains 3 layers (channels) of information about the intensity of red, green and blue light in the image, while BGR is basically the same model with the reversed positions of the first and the third channel. All three channels are usually 8bit unsigned integers with pixel values between 0 and 255. While most image processing software/tools default to the RGB model, OpenCV library uses BGR as default colorspace. Reasons behind this are mostly historical, but they mean that sometimes we have to switch from one to the other to correctly present our results.\n",
    "\n",
    "> RGB and BGR sometimes also refer to different subpixel order of LEDs in monitor and TV panels. While there are some differences between these panel types, this report will only refer to them as data organizational models.\n",
    "> Some image formats support RGBA colorspace with incorporates additional Alpha channel which defines opacity (non-transparency) of individual pixels. This channel usually contains values between 0.0 (= fully transparent pixel) and 1.0 (= fully opaque pixel). However, no image or video format used by UAV cameras supports transparency and saves to this colorspace.\n",
    "\n",
    "The components of the RGB/BGR model are commonly presented graphically in the form of a cube, as shown below:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/af/RGB_color_solid_cube.png\" width=\"400\" />\n",
    "    <figcaption style=\"text-align: center; font-style: italic;\">RGB/BGR colorspace model representation, source: Wikimedia</figcaption>\n",
    "</figure>\n",
    "\n",
    "We can explore these channels by decomposing an example image, and also compare the results to a single-channel grayscale image. A suitable candidate could be **Image 4** due to the variety of tracer particle colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load image into different colorspaces\n",
    "img_path = './1080p/4.jpg'\n",
    "\n",
    "# OpenCV loads to BGR model by default\n",
    "img_bgr = cv2.imread(img_path)\n",
    "\n",
    "# Conversion to grayscale model\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Conversion to RGB model\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Split image into channels\n",
    "b, g, r = cv2.split(img_bgr)\n",
    "\n",
    "fix, ax = plt.subplots(nrows=3, ncols=2, figsize=(9.8, 9))\n",
    "\n",
    "# Matplotlib expects RGB image\n",
    "ax[0][0].imshow(img_rgb)\n",
    "ax[0][0].set_title('Original')\n",
    "\n",
    "ax[1][0].imshow(img_gray)\n",
    "ax[1][0].set_title('Grayscale')\n",
    "\n",
    "ax[2][0].set_visible(False)\n",
    "\n",
    "ax[0][1].imshow(b)\n",
    "ax[0][1].set_title('[B]GR = Blue channel')\n",
    "\n",
    "ax[1][1].imshow(g)\n",
    "ax[1][1].set_title('B[G]R = Green channel')\n",
    "\n",
    "ax[2][1].imshow(r)\n",
    "ax[2][1].set_title('BG[R] = Red channel')\n",
    "\n",
    "# Turn off axes on all images\n",
    "[a.axis('off') for a in ax.reshape(-1)]\n",
    "\n",
    "# Connect all axes to simultaneously change on zoom or pan\n",
    "[a.callbacks.connect('ylim_changed', on_lims_change) for a in ax.reshape(-1)]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Tip:</b> From this point onward, the brackets in colorspace names in the text and figure titles will indicate the selected channel of the mentioned colorspace model - for example R[G]B indicates the green channel of the RGB model.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Figures with axes (images) connected to <span style=\"font-family: Consolas;\">on_lims_change</span> function will change together when ZOOM or PAN are used on any of them.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> Individual image channels and grayscale image above appear to be colored due to the colormap set by the `matplotlib` library which allows for a better contrast. Default `matplotlib` colormap is called `viridis`.\n",
    "\n",
    "We can now notice the differences in local pixel intensities between individual image channels, especially in areas covered by magenta- (around coordinates \\[900, 200\\]) and cyan-colored tracer particles (around \\[1680, 700\\]). While most velocimetry software operates on a single channel image, usually grayscale (described in the following subsection), it's not hard to notice that in the selected case some tracer particles are far more accentuated in \\[R\\]GB and RG\\[B\\] channels than in grayscale. Additionally, we can notice that the water surface is the brightest in the R\\[G\\]B channel (which was to be expected from the original) and darkest and most uniform in the RG\\[B\\] channel (check area around \\[1020, 180\\]). As a rule of thumb, we want the water surface to be uniform and tracer particles to have as much contrast from it as possible.\n",
    "\n",
    "Choosing a suitable image channel for velocimetry analysis could allow for a better quality of tracer particle detection and their motion tracking, and improve the overall velocity estimation accuracy. A candidate strategy for analyzing the video from which the **Image 4** was extracted could also be to perform the image velocimetry on \\[R\\]GB and RG\\[B\\] image channels separately, and then merge the results in the postprocessing stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Tip:</b> Defaulting to a grayscale representation of original color images for image velocimetry does not have to be the best option for each case. Consider using individual RGB image channels if colored tracer particles were used for surface seeding. Even with white/dark tracers, some image channels may even provide better contrast between the image background (water surface) and the particles themselves.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"grayscale\"></a>\n",
    "## 4.2 Grayscale\n",
    "\n",
    "Even though not technically a colorspace, it is often used when a single channel representation of color images is required. Grayscale model aims to describe the human perception of pixel intensities of different colors, i.e., the \"human-perceived achromatic intensity\". For example, conversion of an image from RGB/BGR model to grayscale can be done using a linear combination of its color channels (so called NTSC model):\n",
    "\n",
    "$$ Y = 0.299 R + 0.587 G + 0.114 B, $$\n",
    "\n",
    "Where $Y$ is the grayscale pixel value with $R$, $G$ and $B$ values from individual RGB channels. The previous expression implies (and correctly so) that human perception of red, green, and blue light is not uniform - human eye is more sensitive to green (or green-yellow) color than to blue, which is reflected by the transformation coefficients.\n",
    "\n",
    "Grayscale model is the most commonly used single channel representation of images, but it is not always a good one. For example, we can create an image from RGB value of \\[255, 0, 0\\] on the left half, \\[0, 130, 0\\] in the middle, and \\[0, 81, 251\\] on the right, convert to grayscale and observe the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create images by tiling pixel values\n",
    "img_left = np.tile((255, 0, 0), np.array((300, 150, 1)))\n",
    "img_middle = np.tile((0, 130, 0), np.array((300, 150, 1)))\n",
    "img_right = np.tile((0, 81, 251), np.array((300, 150, 1)))\n",
    "\n",
    "# Merge red and blue image halves\n",
    "img_merged = np.hstack([img_left, img_middle, img_right]).astype('uint8')\n",
    "\n",
    "# Convert RGB to grayscale\n",
    "img_merged_gray = cv2.cvtColor(img_merged, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(9.8, 3.2))\n",
    "\n",
    "# RGB plot\n",
    "ax[0].imshow(img_merged)\n",
    "ax[0].set_title('RGB')\n",
    "\n",
    "# Grayscale plot, set colormap and color range for proper display\n",
    "ax[1].imshow(img_merged_gray, cmap='gray', vmin=0, vmax=255)\n",
    "ax[1].set_title('Grayscale intensity')\n",
    "\n",
    "[a.axis('off') for a in ax.reshape(-1)]\n",
    "[a.callbacks.connect('ylim_changed', on_lims_change) for a in ax.reshape(-1)]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Previous figure demonstrates the potential shortcomings of grayscale channel representation of RGB/BGR images, along with the demonstrations from the previous subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"hsv\"></a>\n",
    "## 4.3 HSV\n",
    "\n",
    "Unlike RGB/BGR model where individual colors intensities are represented in separate image channels, HSV takes a somewhat different approach of separating image data into three channels:\n",
    "\n",
    "1. \\[H\\]SV = **Hue** channel (presented as an angle between 0 and 360 degrees) which represents the **primary (base) color** or **color tone**. Hue angle of 0deg corresponds to the red color, 90deg is yellow, 270deg is blue, etc.\n",
    "2. H\\[S\\]V = **Saturation** channel (0-255 unsigned 8bit integer) which represents amount of gray in the base color, often called **chroma**. When saturation is 0, the resulting color will appear completely \"faded\", and when saturation is 255, the result will be the actual base color.\n",
    "3. HS\\[V\\] = **Value** channel (0-255 unsigned 8bit integer) which represents the color intensity/brightness. When value is 0, the result will be a black pixel, and when value is 255, the result will be completely defined by just the hue and saturation.\n",
    "\n",
    "> OpenCV defines the \\[H\\]SV component in range between 0 and 180deg, as opposed to the more formal definition above. Reasons for this are purely implementational - since both H\\[S\\]V and HS\\[V\\] are 8bit unsigned integers (0-255), creators of the library \"squashed\" the \\[H\\]SV channel range from 360 to 180 (degrees). However, OpenCV also offers a so-called `HSV_full` model, which stretches the \\[H\\]SV channel to range between 0 and 255.\n",
    "\n",
    "Components of the HSV model are commonly graphically presented in the form of a cone, as shown below.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f2/HSV_color_solid_cone.png\" width=\"400\"/>\n",
    "    <figcaption style=\"text-align: center; font-style: italic;\">HSV colorspace model representation, source: Wikimedia</figcaption>\n",
    "</figure>\n",
    "\n",
    "Like with the RGB/BGR model, we can explore these channels by decomposing an example image, and also compare the results to a single channel grayscale image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BGR image loaded in one of the previous code cells\n",
    "img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Split image into channels\n",
    "h, s, v = cv2.split(img_hsv)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(9.8, 9))\n",
    "\n",
    "ax[0][0].imshow(img_rgb)\n",
    "ax[0][0].set_title('Original')\n",
    "\n",
    "ax[1][0].set_visible(False)\n",
    "\n",
    "ax[2][0].imshow(img_gray)\n",
    "ax[2][0].set_title('Grayscale')\n",
    "\n",
    "ax[0][1].imshow(h)\n",
    "ax[0][1].set_title('[H]SV = Hue channel')\n",
    "\n",
    "ax[1][1].imshow(s)\n",
    "ax[1][1].set_title('H[S]V = Saturation channel')\n",
    "\n",
    "ax[2][1].imshow(v)\n",
    "ax[2][1].set_title('HS[V] = Value channel')\n",
    "\n",
    "[a.axis('off') for a in ax.reshape(-1)]\n",
    "[a.callbacks.connect('ylim_changed', on_lims_change) for a in ax.reshape(-1)]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When placed next to each other, grayscale model and HS\\[V\\] channel appear alike - this is not by accident as grayscale is primarily a representation of human perception of color brightness. However, in the case of **Image 4**, tracers in the HS\\[V\\] channel appear to be significantly more pronounced than in the grayscale image, and more equally so for both magenta and cyan particles. H\\[S\\]V channel does not deliver much information and is rather noisy.\n",
    "\n",
    "The \\[H\\]SV channel can actually serve another purpose. We can use the \\[H\\]SV channel information to target and manipulate specific colors in the image. To do so, we should first explore the \\[H\\]SV and H\\[S\\]V components by creating a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate a 64x180px three channel image\n",
    "height, width = 64, 181\n",
    "img = np.ndarray([height, width, 3], dtype='uint8')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9.8, 4))\n",
    "\n",
    "# Assign Hue and Saturation to each pixel\n",
    "for i, j in itertools.product(range(height), range(width)):\n",
    "    img[i, j] = (j, i*4, 255)\n",
    "\n",
    "# Convert HSV image to RGB for plotting\n",
    "ax.imshow(cv2.cvtColor(img, cv2.COLOR_HSV2RGB))\n",
    "ax.set_xlabel('Hue')\n",
    "ax.set_ylabel('Saturation')\n",
    "\n",
    "plt.xticks(np.arange(0, width, step=20))\n",
    "plt.yticks([0, 16, 32, 48, 63], [0, 64, 128, 192, 255])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "HSV model allows us to do something that RGB/BGR does not - to manipulate color hue in order to better grab certain information from RGB channels. For instance, pink-colored tracer particles from **Image 2** have a hue value of about 145 (check by hovering with mouse over these areas in figures above). By manipulating the \\[H\\]SV component, we can \"shift\" hue values (or \"rotate\" the HSV cone around its vertical axis) of all pixels in an image to move certain information to a specific channel - let's try to shift the pink tracers to the red channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load image using different colorspaces\n",
    "img_path = './1080p/2.jpg'\n",
    "img_bgr = cv2.imread(img_path)\n",
    "img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Get the first (red) channel from RGB\n",
    "img_rgb_red = img_rgb[:, :, 0]\n",
    "\n",
    "# Split image into channels\n",
    "h, s, v = cv2.split(img_hsv)\n",
    "\n",
    "# Add 35 to hue channel to move pink to red, and merge to new HSV image.\n",
    "# While channel can be changed with simple addition (h+35), this should be avoided\n",
    "# as it can cause an overflow (value can exceed 255 and be improperly converted).\n",
    "# Function cv2.add() deals with this issue.\n",
    "h_shift = cv2.add(h, 35)\n",
    "\n",
    "# Merge the new HSV image\n",
    "img_hsv_shift = cv2.merge([h_shift, s, v])\n",
    "\n",
    "# Convert to RGB and get the red channel\n",
    "img_rgb_shift = cv2.cvtColor(img_hsv_shift, cv2.COLOR_HSV2RGB)\n",
    "img_rgb_shift_red = img_rgb_shift[:, :, 0]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(9.8, 6.2))\n",
    "\n",
    "ax[0][0].imshow(img_rgb)\n",
    "ax[0][0].set_title('Original RGB')\n",
    "\n",
    "ax[0][1].imshow(img_rgb_shift)\n",
    "ax[0][1].set_title('Hue-shifted RGB')\n",
    "\n",
    "# Only show channel 0, i.e., the red channel\n",
    "ax[1][0].imshow(img_rgb_red)\n",
    "ax[1][0].set_title('Red from original RGB')\n",
    "\n",
    "# Only show channel 0, i.e., the red channel\n",
    "ax[1][1].imshow(img_rgb_shift_red)\n",
    "ax[1][1].set_title('Red from hue-shifted RGB')\n",
    "\n",
    "[a.axis('off') for a in ax.reshape(-1)]\n",
    "[a.callbacks.connect('ylim_changed', on_lims_change) for a in ax.reshape(-1)]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As the figure above demonstrates, by strategically \"shifting\" the hue value we have also modified the RGB contents of the image. Tracer particles that were initially pink have obtained more red color content and are now more pronounced in the \\[R\\]GB channel. Additionally, the red channel has become less sensitive to the yellow colored tracer particles, as these have also moved towards higher hue values (towards the R\\[G\\]B channel).\n",
    "\n",
    "There are other methods of manipulating the HSV colorspace (for example by creating lookup tables) but such strategies can be considerably more complex and worthwhile only in specific cases, thus will not be described in this report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Tip:</b> By \"shifting\" the hue values in the HSV colorspace, we can strategically target specific colors in the image, regardless of their original RGB values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing possible in the HSV colorspace is masking certain image features by using range of hue values. For example, we can split the yellow-colored tracer particles from the background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Yellow hue is around 30, so we can take 30 +/- 10\n",
    "# Saturation lower boundary found by trial and error\n",
    "upper_limit = (40, 255, 255)\n",
    "lower_limit = (20, 60, 0)\n",
    "\n",
    "# Mark pixels in the range defined above, using original HSV\n",
    "mask = cv2.inRange(img_hsv, lower_limit, upper_limit)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(9.8, 3.2))\n",
    "\n",
    "ax[0].imshow(img_rgb)\n",
    "ax[0].set_title('Original RGB')\n",
    "\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title('HSV range filtering for yellow color')\n",
    "\n",
    "[a.axis('off') for a in ax.reshape(-1)]\n",
    "[a.callbacks.connect('ylim_changed', on_lims_change) for a in ax.reshape(-1)]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> It is noticeable that filtering by HSV range also detects some other areas that are not strictly yellow. However, these regions usually do not move and will not be detected by the image velocimetry algorithm. The downside of this approach is that the resulting image is binarized - it contains only zeros (pixels outside the provided HSV range) and ones (pixels inside the defined range). This can lead to particles slightly changing shape between consecutive frames, which can increase the velocity estimation uncertainty.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"lab\"></a>\n",
    "## 4.4 L\\*a\\*b\\*\n",
    "\n",
    "L\\*a\\*b\\* colorspace (sometimes referred to as CIELAB or CIELab) is a three-channel model developed to be a more accurate representation of the human color perception. Components of the model are:\n",
    "\n",
    "1. **L\\*** channel, sometimes referred to as \"L-star\", defines the lightness of the pixels, usually in the range of values between 0 (black) and 100 (white), with maximal chroma values in the middle.\n",
    "2. **a\\*** channel defines the content of base colors between red (+a\\*) and green (-a\\*).\n",
    "3. **b\\*** channel defines the content of base colors between yellow (+b\\*) and blue (-b\\*).\n",
    "\n",
    "> OpenCV library defines L\\*a\\*b\\* channels with values in range 0..255.\n",
    "\n",
    "Like RGB/BGR and HSV, the L\\*a\\*b\\* model has a graphical representation - usually in the form of a sphere.\n",
    "<figure>\n",
    "    <img src=\"https://www.researchgate.net/profile/Pedro-Pardo-4/publication/263697963/figure/fig2/AS:296498639196171@1447702192829/CIE-LAB-1976-color-space.png\" width=\"400\" />\n",
    "    <figcaption style=\"text-align: center; font-style: italic;\">L*a*b* colorspace model representation, (Agudo et al., 2014)</figcaption>\n",
    "</figure>\n",
    "\n",
    "Unlike RGB/BGR, the L\\*a\\*b\\* model covers a broader color gamut, i.e., broader range of colors can be represented with it. We can visualize the individual channels of the L\\*a\\*b\\* colorspace to get a better understanding of how it works (using **Image 4** as an example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_path = './1080p/4.jpg'\n",
    "img_bgr = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Split image into channels\n",
    "l, a, b = cv2.split(img_lab)\n",
    "\n",
    "fix, ax = plt.subplots(nrows=3, ncols=2, figsize=(9.8, 9))\n",
    "\n",
    "ax[0][0].imshow(img_rgb)\n",
    "ax[0][0].set_title('Original')\n",
    "\n",
    "ax[1][0].imshow(img_gray)\n",
    "ax[1][0].set_title('Grayscale')\n",
    "\n",
    "ax[2][0].set_visible(False)\n",
    "\n",
    "ax[0][1].imshow(l)\n",
    "ax[0][1].set_title('[L*]a*b* = Lightness channel')\n",
    "\n",
    "ax[1][1].imshow(a)\n",
    "ax[1][1].set_title('L*[a*]b* = green to red color')\n",
    "\n",
    "ax[2][1].imshow(b)\n",
    "ax[2][1].set_title('L*a*[b*] = blue to yellow color')\n",
    "\n",
    "[a.axis('off') for a in ax.reshape(-1)]\n",
    "[a.callbacks.connect('ylim_changed', on_lims_change) for a in ax.reshape(-1)]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the figure above, it is clear that the \\[L\\*\\]a\\*b\\* channel is perceptually very similar to the grayscale representation and HS\\[V\\]. However, it usually contains a bit more contrast between light and dark image areas than said models. Zooming in on region of cyan-colored tracer particles around coordinates (1620, 700) reveals a somewhat darker water surface and a somewhat lighter particles in the \\[L\\*\\]a\\*b\\* channel than in the grayscale image. Similarly, L\\*\\[a\\*\\]b\\* and L\\*a\\*\\[b\\*\\] channels hold very few visual disturbances from the image background (water surface) and can be used to manually track both magenta- and cyan-colored particles. The downside of using the L\\*\\[a\\*\\]b\\* and L\\*a\\*\\[b\\*\\] channels is that they are often quite blurry, and can require additional manipulations to be a viable model.\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "> Agudo, J., Pardo, P., Sánchez, H., Pérez, Á., & Suero, M. (2014). A Low-Cost Real Color Picker Based on Arduino. In Sensors (Vol. 14, Issue 7, pp. 11943–11956). MDPI AG. https://doi.org/10.3390/s140711943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"conclusions\"></a>\n",
    "## 4.5 Conclusions on colorspace models\n",
    "\n",
    "Access to different colorspace models offers different insights into image data. Instead of defaulting to the well-known grayscale representation, one should also explore different models and their individual channels, and focus the image velocimetry analyses on specific visual information such as tracer particles, or to just maximize the contrast between the image background (water surface) and the foreground (features that are to be tracked). Utilization of HSV and L\\*a\\*b\\* models, in particular, can sometimes be a better alternative than grayscale or RGB/BGR models.\n",
    "\n",
    "Whatever the strategy, the colorspace manipulations should precede the application of any image filtering techniques, some of which are to be described in the following section. To help choose the best colorspace to work with, we can select a suitable sample image with visible tracer particles, and use the code bellow to go output and examine all the described models and their individual channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Select a sample image\n",
    "img_sample_path = './1080p/1.jpg'\n",
    "\n",
    "# Get image extension\n",
    "ext = img_sample_path.split('.')[-1]\n",
    "\n",
    "# Get image directory\n",
    "img_dir = dirname(img_sample_path)\n",
    "\n",
    "# Output directory\n",
    "out_dir = img_dir + '/colorspaces'\n",
    "\n",
    "# Conversions\n",
    "img_sample_bgr = cv2.imread(img_sample_path)\n",
    "img_sample_hsv = cv2.cvtColor(img_sample_bgr, cv2.COLOR_BGR2HSV)\n",
    "img_sample_lab = cv2.cvtColor(img_sample_bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Split into channels\n",
    "rgb_b, rgb_g, rgb_r = cv2.split(img_sample_bgr)\n",
    "hsv_h, hsv_s, hsv_v = cv2.split(img_sample_hsv)\n",
    "lab_l, lab_a, lab_b = cv2.split(img_sample_lab)\n",
    "gray = cv2.cvtColor(img_sample_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a directory in image folder\n",
    "if not exists(out_dir):\n",
    "    mkdir(out_dir)\n",
    "\n",
    "# List all the channels for iterating\n",
    "channels = [\n",
    "    rgb_b, rgb_g, rgb_r,\n",
    "    hsv_h, hsv_s, hsv_v,\n",
    "    lab_l, lab_a, lab_b,\n",
    "    gray\n",
    "]\n",
    "\n",
    "for c in channels:\n",
    "    # Get variable/channel name\n",
    "    c_name = [k for k, v in locals().items() if v is c][0]\n",
    "\n",
    "    # Scale to 0..255\n",
    "    c = (c / c.max() * 255).astype('uint8')\n",
    "\n",
    "    # Apply a colormap for easier inspection\n",
    "    c = cv2.applyColorMap(c, cv2.COLORMAP_VIRIDIS)\n",
    "\n",
    "    # Write channel to the output folder\n",
    "    cv2.imwrite('{}/{}.{}'.format(out_dir, c_name, ext), c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Continue to next chapter: Image filtering >>](image_filtering.ipynb)\n",
    "\n",
    "or\n",
    "\n",
    "[<< Back to MAIN notebook](main.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
